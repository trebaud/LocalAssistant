# ðŸ§  LocalAssistant

> **Use local LLMs with your own tools** âœ¨

![powered by](https://img.shields.io/badge/powered%20by-Ollama-orange)

## ðŸ‘€ What's This?

```
YOU: "What's the weather in Tokyo?"
AI: *actually checks real weather data* "It's 22Â°C and sunny in Tokyo right now."
```

No cap. Your AI assistant can now interact with real tools and APIs without hallucinating responses.

## ðŸš€ Why It Slaps

- ðŸ’¯ **Zero hallucinations** - Gets real data from real sources
- ðŸ”¥ **Plug & play tools** - Weather, location, search, whatever you need
- ðŸ¤¯ **100% locally powered** - Runs on Ollama with zero cloud dependencies
- ðŸ”’ **Privacy first** - No data ever leaves your machine
- ðŸ”Œ **Extensible** - Build and add your own tools

## ðŸƒâ€â™‚ï¸ Get Started in 30 Seconds

```bash
git clone git@github.com:trebaud/LocalAssistant.git

bun install

bun start "What's the weather in Montreal?"
```

## ðŸ§© Make It Your Own

Want to add your own tools? It's stupid simple:

1. Define what your tool does
2. Implement the logic
3. Watch your AI assistant gain new superpowers

## ðŸ¤ Vibe Check

This project is for builders who:
- Want AI that actually *does things* instead of just talking
- Are tired of rate limits and API costs from the big players
- Believe in privacy-first technology with local models
- Love the power of Ollama but want to extend it with real tools
- Want to experiment without a massive learning curve

Built with â¤ï¸, Ollama, and coffee.

---

> **Disclaimer:** LocalAssistant was 100% vibe coded. ðŸ¤–

MIT Licensed â€¢ Contributions Welcome
